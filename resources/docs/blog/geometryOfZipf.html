<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta name="keywords" content="Eben,Kadile,Cowley,Graphics,Mathematics,Math,Julia,Zipf,Law,Geometry,Fourier,Laplace,Beltrami,Weyl" />
    <link rel="stylesheet" type="text/css" href="../../style.css" />
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
	tex2jax: {inlineMath: [["$", "$"],["\\(","\\)"]]},
	errorSetting: {message: undefined}
});
</script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.6/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <title>
        The Geometry of Zipf's Law - Eben Kadile
    </title>
</head>

<body>
    <div class="heading">
        <h1>The Geometry of Zipf's Law</h1>
        <h2>The precise balance between detail and redundancy.</h2>
        <h3>eben.kadile24@gmail.com</h3>
    </div>
    <br>
    <div align="center" style="width:100%">
        <a class="navItem" style="border-top-left-radius:15px;border-bottom-left-radius:15px;" href="../../../index.html">Home</a>
        <a class="navItem" href="../../../Art.html">Art</a>
        <a class="navItem" href="../../../Software.html">Software</a>
        <a class="navItem" href="../../../Blog.html">Blog</a>
        <a class="navItem" style="border-top-right-radius:15px;border-bottom-right-radius:15px;" href="../../../Research.html">Research</a>
    </div>
    <p class="textContent" id="Introduction">
        <big><u><b>Introduction</b>></u></big>
        <br><br>
        Zipf's law is a seemingly mysterious phenomenon which has its origins in linguistics,
        but which is now known to arise in disparate domains including sociology, geology,
        genomics, physics, and even neuroscience. To state the law as it was originally observed
        for languages, let $f_n$ be the frequency (or total number of occurrences) of the nth most
        common word for some language. Then we have the following approximate equation:
        <br><br>
        $$f_n=\frac{f_1}{n}$$
        <br><br>
        Or, taking the logarithm for a more convenient form:
        <br><br>
        $$\log(f_n)=-\log(n)+\log(f_1)$$
        <br><br>
        For example, the most common word in English is "the," the second most common word is "be,"
        and the third most common word is "to." If this law holds, we would expect "be" to
        occur 1/2 as often as "the," and "to" to occur 1/3 as often as "the."
        <br><br>
        In reality, this is not exactly the case. Zipf's law only becomes accurate
        <i>asymptotically,</i> meaning the equations are only really accurate if $n$ is large.
        To demonstrate this, I performed the analysis on the NIV Bible. I plotted my results below,
        and you can find my code, which includes preprocessing a PDF and cleaning the data,
        <a href="https://github.com/Ebanflo42/zipf-bible" target="_blank">here.</a>
        </p>
        <div align="center">
            <img src="../../images/zipf_curve.png" style="border-radius: 5px"/>
        </div>
        <p class="textContent">
            The horizontal axis of this plot corresponds to the logarithm of the nth most common word
            in the Bible, while the vertical axis corresponds to the logarithm of number of occurrences
            of the word. The orange line is the line of best fit for the most common thousand words,
            and the $R^2$ value of $1.00$ signifies that the error of the fit is negligible compared to
            the variance of the data (the statisticians reading this might be skeptical based on the plot,
            but remember that there is a lot more data towards the right).
            <br><br>
            Something which probably stands out at this point is that the many authors of the Bible most
            probably had no idea about exponents, logarithms, lines of best fit, or even equations.
            Indeed, this distribution of words is something that arose completely naturally, and has been
            observed across many different corpuses of text in many different languages. Not only that,
            this distribution has been observed in the magnitude of Earthquakes, the noise spectrum of
            electrical circuits, the sizes of cities, or the frequency of gene sequences in the Zebra fish.
            <br><br>
            Although the ubiquity of this distribution may be initially surprising, there is a significant
            body of literature across different fields which provides a number of different explanations
            for the phenomenon.
            However, there is a specific paper from computational neuroscience,
            <a href="https://www.nature.com/articles/s41586-019-1346-5" target="_blank">Stringer and Pachitariu et al.</a>,
            that contains a proof in its supplementary material, which I believe gets to the heart of the phenomenon
            in a way that is more elegant and enlightening than anything else I have read so far.
            <br><br>
            In order to understand the reasoning of Stringer and Pachitariu, we are going to have to review
            some basic statistics before delving into differential geometry, generalizing the Fourier transform,
            and tying it all back to the nature of <i>representation</i> itself, so buckle up and get ready for
            some spicy math.
        </p>

    </p>
    <div align="center">
        <canvas id="freq2dCanvas" style="height:480px;width:720px"/>
    </div>
    <input type="range" min="-12" max="12" value="2" id="inpxFreq"></input>
    <input type="range" min="-12" max="12" value="-3" id="inpyFreq"></input>
    <br>
    <div align="center">
        <canvas id="freq1dCanvas" style="height:480px;width:720px"/>
    </div>
    <input type="range" min="-12" max="12" value="2" id="inpFreq"></input>
    <br>
    <div align="center">
        <canvas id="highdCanvas" style="height:480px;width:720px"/>
    </div>
    <input type="range" min="0" max="40" value="20" id="expInput"></input>
    <script src="../../scripts/three.min.js"></script>
    <script src="../../scripts/OrbitControls.js"></script>
    <script id="1d_vs" type="glsl">
        void main() {
            gl_Position = projectionMatrix*modelViewMatrix*vec4(position, 1);
        }
    </script>
    <script id="1d_fs" type="glsl">
        void main() { gl_FragColor = vec4(0.2, 0.8, 0.2, 1.0); }
    </script>
    <script id="2d_vs" type="glsl">
        void main() {
          gl_Position = vec4(position, 1.0);
        }
    </script>
    <script id="2d_fs" type="glsl">
        uniform vec2 res;
        uniform vec2 freqs;

        const float pi = 4.0*atan(1.0);

        vec3 colormap(float val, float scale) {
            val /= scale;
            return vec3(max(0.0, val), 0.15*abs(val), -min(0.0, val));
        }

        vec3 render(vec2 coords) {
            vec2 s = sin(2.0*pi*freqs*coords/res);
            return colormap(s.x * s.y, 1.0);
        }

        void main(){
            gl_FragColor = vec4(0, 0, 0, 1);
            for(int i = 0; i < 2; i++){
                for(int j = 0; j < 2; j++){
                    gl_FragColor.rgb += render(gl_FragCoord.xy + vec2(i, j));
                }
            }
            gl_FragColor *= 0.25;
	    }
    </script>
    <script id="highd_vs" type="glsl">
        attribute vec3 vertCol;
        varying vec3 fragCol;
        void main() {
            gl_Position = projectionMatrix*modelViewMatrix*vec4(position, 1);
            fragCol = vertCol;
        }
    </script>
    <script id="highd_fs" type="glsl">
        uniform float p;
        varying vec3 fragCol;
        void main(){
            vec3 pows = pow(fragCol, vec3(1.0 - p));
            float n = pow(pows.x + pows.y + pows.z, 1.0/(1.0 - p));
            vec3 new_col = fragCol/n;
            gl_FragColor = vec4(new_col, 1);
        }
    </script>
    <script src="../../scripts/displayZipfGeometry.js"></script>
</body>